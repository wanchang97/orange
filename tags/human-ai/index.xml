<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>human-ai on Lil&#39;Log</title>
    <link>https://lilianweng.github.io/tags/human-ai/</link>
    <description>Recent content in human-ai on Lil&#39;Log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 05 Feb 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://lilianweng.github.io/tags/human-ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Thinking about High-Quality Human Data</title>
      <link>https://lilianweng.github.io/posts/2024-02-05-human-data-quality/</link>
      <pubDate>Mon, 05 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>https://lilianweng.github.io/posts/2024-02-05-human-data-quality/</guid>
      <description>[Special thank you to Ian Kivlichan for many useful pointers (E.g. the 100+ year old Nature paper &amp;ldquo;Vox populi&amp;rdquo;) and nice feedback. üôè ]
High-quality data is the fuel for modern data deep learning model training. Most of the task-specific labeled data comes from human annotation, such as classification task or RLHF labeling (which can be constructed as classification format) for LLM alignment training. Lots of ML techniques in the post can help with data quality, but fundamentally human data collection involves attention to details and careful execution.</description>
    </item>
    
  </channel>
</rss>
